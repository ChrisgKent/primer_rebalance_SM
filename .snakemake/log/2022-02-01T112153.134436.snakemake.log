Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                count    min threads    max threads
---------------  -------  -------------  -------------
all                    1              1              1
amplicon_parser        1              1              1
coverage               1              1              1
total                  3              1              1

Select jobs to execute...

[Tue Feb  1 11:21:53 2022]
rule amplicon_parser:
    input: /Users/chriskent/V5_run/V5_analysis/V5.primer.bed
    output: results/amplicons.bed
    jobid: 2
    resources: tmpdir=/var/folders/tj/dbg1wcw533d_t688g3kljt1m0000gn/T

[Tue Feb  1 11:21:59 2022]
Finished job 2.
1 of 3 steps (33%) done
Select jobs to execute...

[Tue Feb  1 11:21:59 2022]
rule coverage:
    input: results/amplicons.bed
    output: results/coverage/[].bed
    jobid: 1
    wildcards: bed=[]
    resources: tmpdir=/var/folders/tj/dbg1wcw533d_t688g3kljt1m0000gn/T

RuleException in line 30 of /Users/chriskent/primer_rebalance_SM/workflow/Snakefile:
NameError: The name 'scheme' is unknown in this context. Please make sure that you defined that variable. Also note that braces not used for variable access have to be escaped by repeating them, i.e. {{print $1}}
